{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c43e3e07",
   "metadata": {},
   "source": [
    "# <u><b>Advanced Analysis For Stroke Prediction Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00464d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import plotly.express as ex\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as pyo\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02a0767",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('D:/3rd Year - 2nd Semester/ST 3082 - Statistical Learning I/Data Analysis Final Project/Stroke Prediction/healthcare-dataset-stroke-data.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325c2c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['id'],axis=1,inplace=True)\n",
    "data['work_type'] = data['work_type'].replace('Self-employed', 'Self_employed')\n",
    "data['smoking_status'] = data['smoking_status'].replace('formerly smoked', 'formerly_smoked')\n",
    "data['smoking_status'] = data['smoking_status'].replace('never smoked', 'never_smoked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f58c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the other from gender\n",
    "data.drop(data[data['gender'] == 'Other'].index, inplace = True)\n",
    "data[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df420ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "\n",
    "DT_bmi_pipe = Pipeline( steps=[ \n",
    "                               ('scale',StandardScaler()),\n",
    "                               ('lr',DecisionTreeRegressor(random_state=42))\n",
    "                              ])\n",
    "X = data[['age','gender','ever_married','Residence_type','bmi']].copy()\n",
    "X.gender = X.gender.replace({'Male':0,'Female':1}).astype(np.uint8)\n",
    "X.Residence_type = X.Residence_type.replace({'Urban':0,'Rural':1}).astype(np.uint8)\n",
    "X.ever_married = X.ever_married.replace({'No':0,'Yes':1}).astype(np.uint8)\n",
    "Missing = X[X.bmi.isna()]\n",
    "X = X[~X.bmi.isna()]\n",
    "Y = X.pop('bmi')\n",
    "DT_bmi_pipe.fit(X,Y)\n",
    "predicted_bmi = pd.Series(DT_bmi_pipe.predict(Missing[['age','gender','ever_married','Residence_type']]),index=Missing.index)\n",
    "data.loc[Missing.index,'bmi'] = predicted_bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1236ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status'], drop_first=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be799330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling the dataset before model development\n",
    "data = data.sample(frac = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0016c14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)  # set the random seed for reproducibility\n",
    "\n",
    "X = data.drop(['stroke'], axis=1)\n",
    "y = data['stroke']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83325448",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa85dd9b",
   "metadata": {},
   "source": [
    "# Using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa9501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sampler = SMOTE(random_state = 42)\n",
    "\n",
    "X_train,y_train= sampler.fit_resample(X_train,y_train)\n",
    "y_tr = pd.DataFrame({'stroke':y_train}) #y_tr is used just to draw graph\n",
    "sns.countplot(data = y_tr, x = 'stroke', y= None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f67273",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Libraries for Modedl Fitting\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, classification_report, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4297c229",
   "metadata": {},
   "source": [
    "### Defining Functions to easily create Confusion matric and ROC curve for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebe6361",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function For ROC Curve\n",
    "#Inputs are y_test and y_prob\n",
    "#Make sure to calculate y_prob in each model before generating ROC curve\n",
    "\n",
    "def plot_ROC(y_test, y_prob):\n",
    "    from sklearn import metrics\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\n",
    "    roc_auc = metrics.auc(false_positive_rate, true_positive_rate)\n",
    "    sns.set_theme(style = 'white')\n",
    "    plt.figure(figsize = (3, 3))\n",
    "    plt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\n",
    "    plt.axis('tight')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3cd5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function For Confusion matrix\n",
    "\n",
    "def plot_confusion_matrix(y_test, y_pred):\n",
    "    acc = round(accuracy_score(y_test, y_pred), 2)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\".0f\")\n",
    "    plt.xlabel('y_pred')\n",
    "    plt.ylabel('y_test')\n",
    "    plt.title('Accuracy Score: {0}'.format(acc), size=10)\n",
    "    plt.show(block=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d66e13",
   "metadata": {},
   "source": [
    "## <u>Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d749ddd",
   "metadata": {},
   "source": [
    "### <u> Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de151d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR=LogisticRegression()\n",
    "logistic_model = LR.fit(X_train,y_train)\n",
    "y_pred=logistic_model.predict(X_test)\n",
    "class_report=classification_report(y_test,y_pred)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa925f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Using the function that we defined above to create ROC \n",
    "\n",
    "y_prob = logistic_model.predict_proba(X_test)[:,1]\n",
    "plot_ROC(y_test, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dc21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Using the function that we defined above to create confusion matrix\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3e1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying to check overfiitng by predicting training set\n",
    "\n",
    "y_pred=logistic_model.predict(X_train)\n",
    "class_report=classification_report(y_train,y_pred)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007db4a7",
   "metadata": {},
   "source": [
    "## <u>KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b6be92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model = KNeighborsClassifier().fit(X_train,y_train)\n",
    "y_pred = knn_model.predict(X_test)\n",
    "y_prob = knn_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f822189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Using the function that we defined above to create ROC and confusion matrix\n",
    "\n",
    "y_prob = knn_model.predict_proba(X_test)[:,1]\n",
    "plot_ROC(y_test, y_prob)\n",
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f2104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying to check overfiitng by predicting training set\n",
    "\n",
    "y_pred=knn_model.predict(X_train)\n",
    "class_report=classification_report(y_train,y_pred)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3d0898",
   "metadata": {},
   "source": [
    "## <u> SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb8feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(random_state = 42, probability = True)\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c08d5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Using the function that we defined above to create ROC and confusion matrix\n",
    "\n",
    "y_prob = svc.predict_proba(X_test)[:,1]\n",
    "plot_ROC(y_test, y_prob)\n",
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c191a92a",
   "metadata": {},
   "source": [
    "## <u> Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa45424",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state = 42, max_depth = 5)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "y_prob = rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aa97c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Using the function that we defined above to create ROC and confusion matrix\n",
    "\n",
    "y_prob = rf.predict_proba(X_test)[:,1]\n",
    "plot_ROC(y_test, y_prob)\n",
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87696de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "f_imp3 = pd.DataFrame(columns = ['feature', 'importance'], index = range(15))\n",
    "for i in range(len(f_imp3.index)):\n",
    "    f_imp3.iloc[i, 0] = X_train.columns.to_list()[i]\n",
    "f_imp3['importance'] = rf.feature_importances_\n",
    "f_imp3 = f_imp3.sort_values('importance', ascending = False)\n",
    "f_imp3[0:12].style.background_gradient(cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a17c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import (partial_dependence, \n",
    "                                PartialDependenceDisplay)\n",
    "var = 'age'\n",
    "PartialDependenceDisplay.from_estimator(rf, X_train, [var]);\n",
    "PartialDependenceDisplay.from_estimator(rf, X_train, ['bmi']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38b6e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PartialDependenceDisplay.from_estimator(rf, X_train, ['avg_glucose_level']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b481bc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "# Define the parameter distributions for hyperparameter tuning\n",
    "param_distributions = {\n",
    "    'n_estimators': np.arange(10, 200, 10),  # Number of trees in the forest\n",
    "    'max_depth': [None] + list(np.arange(5, 30, 5)),  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None]  # Number of features to consider when looking for the best split\n",
    "}\n",
    "\n",
    "# Create the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(rf, param_distributions, n_iter=100, cv=5, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameter values\n",
    "best_params = random_search.best_params_\n",
    "print(\"Best Hyperparameters: \", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a45225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new instance of RandomForestClassifier with the best hyperparameter values\n",
    "best_rf = RandomForestClassifier(random_state=42,\n",
    "                                n_estimators=best_params['n_estimators'],\n",
    "                                max_depth=best_params['max_depth'],\n",
    "                                min_samples_split=best_params['min_samples_split'],\n",
    "                                min_samples_leaf=best_params['min_samples_leaf'],\n",
    "                                max_features=best_params['max_features'])\n",
    "\n",
    "# Fit the best_rf to the training data\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict with the best_rf\n",
    "y_pred = best_rf.predict(X_test)\n",
    "y_prob = best_rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Evaluate the performance of the tuned model\n",
    "# Add your evaluation code here\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6c4579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "f_imp3 = pd.DataFrame(columns = ['feature', 'importance'], index = range(15))\n",
    "for i in range(len(f_imp3.index)):\n",
    "    f_imp3.iloc[i, 0] = X_train.columns.to_list()[i]\n",
    "f_imp3['importance'] = best_rf.feature_importances_\n",
    "f_imp3 = f_imp3.sort_values('importance', ascending = False)\n",
    "f_imp3[0:12].style.background_gradient(cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d858b51c",
   "metadata": {},
   "source": [
    "## <u>XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f32803",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(random_state = 42, max_depth = 5, objective = 'binary:logistic', eval_metric = 'logloss')\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_prob = xgb.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6c6c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Using the function that we defined above to create ROC and confusion matrix\n",
    "\n",
    "y_prob =xgb.predict_proba(X_test)[:,1]\n",
    "plot_ROC(y_test, y_prob)\n",
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaf8b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "f_imp3 = pd.DataFrame(columns = ['feature', 'importance'], index = range(15))\n",
    "for i in range(len(f_imp3.index)):\n",
    "    f_imp3.iloc[i, 0] = X_train.columns.to_list()[i]\n",
    "f_imp3['importance'] = xgb.feature_importances_\n",
    "f_imp3 = f_imp3.sort_values('importance', ascending = False)\n",
    "f_imp3[0:12].style.background_gradient(cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3b3f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter distribution for randomized search\n",
    "param_dist = {\n",
    "    'max_depth': np.arange(3, 7),  # Example values for max_depth\n",
    "    'learning_rate': np.logspace(-3, 0, num=100),  # Example values for learning_rate\n",
    "    'n_estimators': np.arange(100, 400, 50),  # Example values for n_estimators\n",
    "    # Add more hyperparameters to tune as needed\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier model\n",
    "#xgb = XGBClassifier(random_state=42, objective='binary:logistic', eval_metric='logloss')\n",
    "\n",
    "# Perform Randomized Search Cross Validation (RandomizedSearchCV) for hyperparameter tuning\n",
    "random_search = RandomizedSearchCV(estimator=xgb, param_distributions=param_dist, cv=5,\n",
    "                                   n_iter=10, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the RandomizedSearchCV\n",
    "best_params = random_search.best_params_\n",
    "print(\"Best Hyperparameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5927cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the XGBClassifier model with the best hyperparameters\n",
    "best_xgb = XGBClassifier(random_state=42, objective='binary:logistic', eval_metric='logloss',\n",
    "                         max_depth=best_params['max_depth'],\n",
    "                         learning_rate=best_params['learning_rate'],\n",
    "                         n_estimators=best_params['n_estimators'])\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with the tuned model\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "y_prob = best_xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the performance of the tuned model\n",
    "# Add your evaluation code here\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173d1be6",
   "metadata": {},
   "source": [
    "## <u> AdaBoost Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b372a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ada = AdaBoostClassifier(n_estimators=2000, random_state = 42)\n",
    "Ada.fit(X_train, y_train)\n",
    "y_pred = Ada.predict(X_test)\n",
    "y_prob = Ada.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a188dda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Using the function that we defined above to create ROC and confusion matrix\n",
    "\n",
    "y_prob =Ada.predict_proba(X_test)[:,1]\n",
    "plot_ROC(y_test, y_prob)\n",
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc315d72",
   "metadata": {},
   "source": [
    "## <u> CatBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d484d693",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CatBoostClassifier(logging_level='Silent')\n",
    "cat.fit(X_train, y_train)\n",
    "y_pred = cat.predict(X_test)\n",
    "y_prob = cat.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8996ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Using the function that we defined above to create ROC and confusion matrix\n",
    "\n",
    "y_prob =cat.predict_proba(X_test)[:,1]\n",
    "plot_ROC(y_test, y_prob)\n",
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf73728c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f2f441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84104391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee872225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f762d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
